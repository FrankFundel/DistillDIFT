# DistillDIFT
Distilling the capability of large diffusion models for semantic correspondence.

# ToDo
1. Replicate Hedlin et al.: https://github.com/ubc-vision/LDM_correspondences
2. Replicate Tang et al.: https://github.com/Tsingularity/dift
3. Replicate Zhang et al.: https://github.com/Junyi42/sd-dino
4. Replicate Luo et al.: https://github.com/diffusion-hyperfeatures/diffusion_hyperfeatures
