{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Correspondence with Synthetic 3D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pytorch3d.implicitron.tools.config import expand_args_fields\n",
    "from pytorch3d.implicitron.dataset.json_index_dataset import JsonIndexDataset\n",
    "from pytorch3d.implicitron.dataset.visualize import get_implicitron_sequence_pointcloud\n",
    "from pytorch3d.implicitron.tools.point_cloud_utils import render_point_cloud_pytorch3d\n",
    "\n",
    "# Setup dataset root and paths\n",
    "_CO3DV2_DATASET_ROOT = \"/export/group/datasets/co3d\"\n",
    "category = \"skateboard\"\n",
    "dataset_root = _CO3DV2_DATASET_ROOT\n",
    "frame_file = os.path.join(dataset_root, category, \"frame_annotations.jgz\")\n",
    "sequence_file = os.path.join(dataset_root, category, \"sequence_annotations.jgz\")\n",
    "image_size = 256\n",
    "\n",
    "# Initialize dataset\n",
    "expand_args_fields(JsonIndexDataset)\n",
    "dataset = JsonIndexDataset(\n",
    "    frame_annotations_file=frame_file,\n",
    "    sequence_annotations_file=sequence_file,\n",
    "    dataset_root=dataset_root,\n",
    "    image_height=image_size,\n",
    "    image_width=image_size,\n",
    "    load_point_clouds=True,\n",
    "    box_crop=False,\n",
    "    mask_images=False,\n",
    "    load_images=True,\n",
    "    load_masks=True\n",
    ")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "from pytorch3d.implicitron.tools.point_cloud_utils import _transform_points, PointsRasterizer, PointsRasterizationSettings\n",
    "\n",
    "def get_depth_point_cloud_pytorch3d(\n",
    "    camera,\n",
    "    point_cloud,\n",
    "    render_size: Tuple[int, int],\n",
    "    point_radius: float = 0.03,\n",
    "    topk: int = 10,\n",
    "    eps: float = 1e-2,\n",
    "    bin_size: Optional[int] = None,\n",
    "    **kwargs,\n",
    "):\n",
    "    # move to the camera coordinates; using identity cameras in the renderer\n",
    "    point_cloud = _transform_points(camera, point_cloud, eps, **kwargs)\n",
    "    camera_trivial = camera.clone()\n",
    "    camera_trivial.R[:] = torch.eye(3)\n",
    "    camera_trivial.T *= 0.0\n",
    "\n",
    "    bin_size = (\n",
    "        bin_size\n",
    "        if bin_size is not None\n",
    "        else (64 if int(max(render_size)) > 1024 else None)\n",
    "    )\n",
    "    rasterizer = PointsRasterizer(\n",
    "        cameras=camera_trivial,\n",
    "        raster_settings=PointsRasterizationSettings(\n",
    "            image_size=render_size,\n",
    "            radius=point_radius,\n",
    "            points_per_pixel=topk,\n",
    "            bin_size=bin_size,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    fragments = rasterizer(point_cloud, **kwargs)\n",
    "    return fragments.zbuf.min(dim=-1)[0].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pytorch3d.renderer.cameras import get_screen_to_ndc_transform\n",
    "\n",
    "def get_sample(max_frames=16):\n",
    "    # 1. Sample random sequence from dataset\n",
    "    random_index = 0 #torch.randint(0, len(dataset.seq_annots.keys()), (1,)).item()\n",
    "    sequence_name = list(dataset.seq_annots.keys())[random_index]\n",
    "    point_cloud, sequence_frame_data = get_implicitron_sequence_pointcloud(\n",
    "        dataset,\n",
    "        sequence_name=sequence_name,\n",
    "        mask_points=True,\n",
    "        max_frames=max_frames,\n",
    "        num_workers=1,\n",
    "        load_dataset_point_cloud=True,\n",
    "    )\n",
    "    point_cloud = point_cloud.to(device)\n",
    "\n",
    "    # 2. Sample two random frames from the sequence\n",
    "    frame_indices = torch.randint(0, len(sequence_frame_data.frame_number), (2,))\n",
    "    source_idx, target_idx = frame_indices\n",
    "    source_image = sequence_frame_data.image_rgb[source_idx]\n",
    "    source_camera = sequence_frame_data.camera.to(device)[source_idx.item()]\n",
    "    target_image = sequence_frame_data.image_rgb[target_idx]\n",
    "    target_camera = sequence_frame_data.camera.to(device)[target_idx.item()]\n",
    "\n",
    "    # 4. Render source and target images\n",
    "    source_image_render, _, _ = render_point_cloud_pytorch3d(\n",
    "        source_camera,\n",
    "        point_cloud,\n",
    "        render_size=(image_size, image_size),\n",
    "        point_radius=2e-2,\n",
    "        topk=10,\n",
    "        bg_color=1.0,\n",
    "        bin_size=0,\n",
    "    )\n",
    "    source_rendered_image = source_image_render[0].clamp(0.0, 1.0).cpu()\n",
    "\n",
    "    depth_rendered = get_depth_point_cloud_pytorch3d(\n",
    "        source_camera,\n",
    "        point_cloud,\n",
    "        render_size=(image_size, image_size),\n",
    "        point_radius=2e-2,\n",
    "        topk=10,\n",
    "        bin_size=0,\n",
    "    )\n",
    "\n",
    "    target_image_render, _, _ = render_point_cloud_pytorch3d(\n",
    "        target_camera,\n",
    "        point_cloud,\n",
    "        render_size=(image_size, image_size),\n",
    "        point_radius=2e-2,\n",
    "        topk=10,\n",
    "        bg_color=1.0,\n",
    "        bin_size=0,\n",
    "    )\n",
    "    target_rendered_image = target_image_render[0].clamp(0.0, 1.0).cpu()\n",
    "\n",
    "    # 5. Determine corresponding point on target image using point cloud and camera info\n",
    "    depth_rendered = depth_rendered[0].squeeze(0)\n",
    "    nz_indices = (depth_rendered > 0).nonzero()\n",
    "    depth_values = depth_rendered[nz_indices[:, 0], nz_indices[:, 1]]\n",
    "    source_points = torch.stack((nz_indices[:, 0], nz_indices[:, 1], depth_values), dim=1) # Y, X, Z in screen space\n",
    "\n",
    "    source_points_3d = source_points[:, [1, 0, 2]] # X, Y, Z in screen space\n",
    "    source_points_3d = get_screen_to_ndc_transform(source_camera, image_size=(image_size, image_size), with_xyflip=True).transform_points(source_points_3d) # X, Y, Z in NDC\n",
    "\n",
    "    source_points_3d = source_camera.unproject_points(source_points_3d, world_coordinates=True, from_ndc=True) # X, Y, Z in world space\n",
    "    target_points_3d = target_camera.transform_points_screen(source_points_3d, image_size=(image_size, image_size)) # Y, X, Z in screen space\n",
    "    target_points = target_points_3d[:, [1, 0]].long().clamp(0, image_size - 1)\n",
    "\n",
    "    source_points = source_camera.transform_points_screen(source_points_3d, image_size=(image_size, image_size)) # Y, X, Z in screen space\n",
    "    source_points = source_points[:, [1, 0]].long().clamp(0, image_size - 1)\n",
    "\n",
    "    # rainbow color map\n",
    "    cmap = plt.get_cmap(\"rainbow\")\n",
    "    colors = cmap(torch.linspace(0, 1, source_points.shape[0]))\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
    "    ax[0, 0].imshow(source_image.permute(1, 2, 0))\n",
    "    #source_color_map = torch.zeros_like(source_image).permute(1, 2, 0)\n",
    "    #source_color_map[source_points[:, 0], source_points[:, 1]] = torch.tensor(colors, dtype=torch.float)[:, :3]\n",
    "    #ax[0, 0].imshow(source_color_map, cmap=\"rainbow\", alpha=0.5)\n",
    "    ax[0, 0].scatter(source_points[:, 1].cpu(), source_points[:, 0].cpu(), c=colors, s=1, alpha=[0.1] * len(source_points))\n",
    "    ax[0, 0].axis(\"off\")\n",
    "    ax[0, 1].imshow(target_image.permute(1, 2, 0))\n",
    "    #target_color_map = torch.zeros_like(target_image).permute(1, 2, 0)\n",
    "    #target_color_map[target_points[:, 0], target_points[:, 1]] = torch.tensor(colors, dtype=torch.float)[:, :3]\n",
    "    #ax[0, 1].imshow(target_color_map, cmap=\"rainbow\", alpha=0.5)\n",
    "    ax[0, 1].scatter(target_points[:, 1].cpu(), target_points[:, 0].cpu(), c=colors, s=1, alpha=[0.1] * len(source_points))\n",
    "    ax[0, 1].axis(\"off\")\n",
    "    ax[1, 0].imshow(source_rendered_image.permute(1, 2, 0))\n",
    "    ax[1, 0].scatter(source_points[:, 1].cpu(), source_points[:, 0].cpu(), c=colors, s=1, alpha=[0.1] * len(source_points))\n",
    "    #ax[1, 0].imshow(source_color_map, cmap=\"rainbow\", alpha=0.5)\n",
    "    ax[1, 0].axis(\"off\")\n",
    "    ax[1, 1].imshow(target_rendered_image.permute(1, 2, 0))\n",
    "    #ax[1, 1].imshow(target_color_map, cmap=\"rainbow\", alpha=0.5)\n",
    "    ax[1, 1].scatter(target_points[:, 1].cpu(), target_points[:, 0].cpu(), c=colors, s=1, alpha=[0.1] * len(source_points))\n",
    "    ax[1, 1].axis(\"off\")\n",
    "\n",
    "get_sample()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distilldift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
