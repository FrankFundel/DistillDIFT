{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=5\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.dataset import read_dataset_config, load_dataset, Preprocessor\n",
    "from utils.model import read_model_config, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'dataset_config.yaml'\n",
    "dataset_name = 'SPair-71k'\n",
    "image_size = (768, 768)\n",
    "model_config = 'eval_config.yaml'\n",
    "model_name = 'diff_sd2-1_hook'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = read_dataset_config(config_path)\n",
    "config = dataset_config[dataset_name]\n",
    "\n",
    "preprocess = Preprocessor(image_size=image_size, image_range=[-1, 1], rescale_data=False, flip_data=False, normalize_image=False)\n",
    "dataset = load_dataset(dataset_name, config, preprocess)\n",
    "if hasattr(dataset, 'category_to_id'):\n",
    "    dataset.create_category_to_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = read_model_config(model_config)[model_name]\n",
    "model = load_model(model_name, model_config)\n",
    "model.eval()\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attn(Q, K, V=None):\n",
    "    attn = torch.matmul(Q, K.transpose(-1, -2))\n",
    "    attn = attn / torch.sqrt(torch.tensor(Q.shape[-1]).float())\n",
    "    attn = torch.nn.functional.softmax(attn, dim=-1)\n",
    "    #attn = torch.matmul(attn, V)\n",
    "    return attn.transpose(-1, -2)\n",
    "\n",
    "def plot_attention_maps(sample, prompt_prefix='a photo of a ', block=0):\n",
    "    prompt = prompt_prefix + sample['source_category']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = model.get_features(sample['source_image'].unsqueeze(0).to(\"cuda\"), [prompt])\n",
    "\n",
    "    Q = features[block*3]\n",
    "    K = features[block*3+1]\n",
    "    V = features[block*3+2]\n",
    "    print(Q.shape, K.shape, V.shape)\n",
    "\n",
    "    vocab = model.extractor.pipe.tokenizer.get_vocab()\n",
    "    vocab = {v: k for k, v in vocab.items()}\n",
    "    tokens = [vocab[t] for t in model.extractor.pipe.tokenizer.encode(prompt)[1:-1]] # remove <s> and </s>\n",
    "\n",
    "    fig, ax = plt.subplots(1, len(tokens)+1, figsize=(20, 5))\n",
    "    ax[0].imshow(Image.open(sample['source_image_path']))\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    A = attn(Q, K)\n",
    "    for i, t in enumerate(tokens):\n",
    "        size = int(A.shape[-1] ** .5)\n",
    "        attn_map = A[0, i+1].reshape(size, size)\n",
    "        attn_map = (attn_map - attn_map.min()) / (attn_map.max() - attn_map.min())\n",
    "        attn_map = torch.nn.functional.interpolate(attn_map.unsqueeze(0).unsqueeze(0), size=(768, 768), mode='bilinear').squeeze(0).squeeze(0)\n",
    "        ax[i+1].imshow(attn_map.cpu().numpy(), cmap='hot')\n",
    "        ax[i+1].set_title(t)\n",
    "        ax[i+1].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    plot_attention_maps(dataset[0], prompt_prefix='front side of a ', block=i)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distilldift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
